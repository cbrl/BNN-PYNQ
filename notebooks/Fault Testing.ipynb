{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fault Injection on Quantized Neural Networks\n",
    "\n",
    "This notebook tests fault injection on quantized neural networks (QNNs). It is recommended to first read through and understand some of the example notebooks that demonstrate image classification with BNN-PYNQ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import the packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "require(['notebook/js/codecell'], function(codecell) {\n",
       "  codecell.CodeCell.options_default.highlight_modes[\n",
       "      'magic_text/x-csrc'] = {'reg':[/^%%microblaze/]};\n",
       "  Jupyter.notebook.events.one('kernel_ready.Kernel', function(){\n",
       "      Jupyter.notebook.get_cells().map(function(cell){\n",
       "          if (cell.cell_type == 'code'){ cell.auto_highlight(); } }) ;\n",
       "  });\n",
       "});\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import bnn\n",
    "import os\n",
    "import csv\n",
    "from copy import deepcopy\n",
    "from json import dumps\n",
    "from PIL import Image\n",
    "from yapf.yapflib.yapf_api import FormatCode\n",
    "import scipy.io as sio\n",
    "import matplotlib.pyplot as plt\n",
    "from pynq import Xlnk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load the required datasets\n",
    "\n",
    "This notebook utilizes the CIFAR-10, GTSRB, SVHN, and MNIST datasets. You can download them from each given url via wget and unzip it to a folder on Pynq as shown below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CIFAR-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cifar10_testset(folder, num_images=10000):\n",
    "    num_images = min(num_images, 10000)\n",
    "\n",
    "    input_file = ''\n",
    "    if num_images == 10000:\n",
    "        input_file = folder + \"/test_batch.bin\"\n",
    "    else:\n",
    "        input_file = folder + \"/test_batch_{}\".format(num_images) + \".bin\"\n",
    "\n",
    "    if not os.path.exists(input_file):\n",
    "        with open(folder + \"/test_batch.bin\", \"rb\") as infile:\n",
    "            with open(input_file, \"wb+\") as outfile:\n",
    "                for i in range(num_images):\n",
    "                    outfile.write(infile.read(3073))\n",
    "\n",
    "    labels = []\n",
    "    with open(input_file, \"rb\") as file:\n",
    "        for i in range(num_images):\n",
    "            #read first byte -> label\n",
    "            labels.append(int.from_bytes(file.read(1), byteorder=\"big\"))\n",
    "            #read image (3072 bytes) and do nothing with it\n",
    "            file.read(3072)\n",
    "        file.close()\n",
    "\n",
    "    return (input_file, labels)\n",
    "\n",
    "\n",
    "if not os.path.exists(\"/home/xilinx/jupyter_notebooks/bnn/cifar-10-binary.tar.gz\"):\n",
    "    !wget https://www.cs.toronto.edu/~kriz/cifar-10-binary.tar.gz\n",
    "\n",
    "if not os.path.exists(\"/home/xilinx/jupyter_notebooks/bnn/cifar-10-batches-bin/\"):\n",
    "    !tar -xf cifar-10-binary.tar.gz\n",
    "\n",
    "cifar_files, cifar_labels = load_cifar10_testset(\"/home/xilinx/jupyter_notebooks/bnn/cifar-10-batches-bin/\", 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GTSRB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_gtsrb_testset(folder, num_images=12630):\n",
    "    num_images = min(num_images, 12630)\n",
    "\n",
    "    image_files = []\n",
    "    images = []\n",
    "    labels = []\n",
    "\n",
    "    with open(folder + \"/GT-final_test.csv\") as gtfile:\n",
    "        gtreader = csv.reader(gtfile, delimiter=';')\n",
    "        next(gtreader)\n",
    "        for row in gtreader:\n",
    "            image_files.append(folder + '/' + row[0])\n",
    "            labels.append(int(row[7]))\n",
    "\n",
    "    labels = labels[0:num_images]\n",
    "    for i in range(num_images):\n",
    "        images.append(Image.open(image_files[i]))\n",
    "        images[i].load()\n",
    "\n",
    "    return (images, labels)\n",
    "\n",
    "\n",
    "if not os.path.exists(\"/home/xilinx/jupyter_notebooks/bnn/GTSRB_Final_Test_Images.zip\"):\n",
    "    !wget https://sid.erda.dk/public/archives/daaeac0d7ce1152aea9b61d9f1e19370/GTSRB_Final_Test_Images.zip\n",
    "\n",
    "if not os.path.exists(\"/home/xilinx/jupyter_notebooks/bnn/GTSRB_Final_Test_GT.zip\"):\n",
    "    !wget https://sid.erda.dk/public/archives/daaeac0d7ce1152aea9b61d9f1e19370/GTSRB_Final_Test_GT.zip\n",
    "\n",
    "if not os.path.exists(\"/home/xilinx/jupyter_notebooks/bnn/GTSRB\"):\n",
    "    !unzip -q -o GTSRB_Final_Test_Images.zip\n",
    "    !unzip -q -o GTSRB_Final_Test_GT.zip\n",
    "    !mv GT-final_test.csv GTSRB/Final_Test/Images\n",
    "\n",
    "gtsrb_files, gtsrb_labels = load_gtsrb_testset(\"/home/xilinx/jupyter_notebooks/bnn/GTSRB/Final_Test/Images\", 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVHN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_svhn_testset(file, num_images=26032):\n",
    "    num_images = min(num_images, 26032)\n",
    "\n",
    "    images = []\n",
    "    labels = []\n",
    "\n",
    "    data = sio.loadmat(file)\n",
    "\n",
    "    # Subtact 1 to match classifier output. E.g. The classifier will return class 1 for an image of the number 2.\n",
    "    label_mat = data['y'] - 1\n",
    "    image_mat = data['X']\n",
    "\n",
    "    labels = label_mat.transpose().tolist()[0]\n",
    "    labels = labels[0:num_images]\n",
    "\n",
    "    #for i in range(image_mat.shape[3]):\n",
    "    for i in range(num_images):\n",
    "        images.append(Image.fromarray(image_mat[:,:,:,i]))\n",
    "        images[i].load()\n",
    "\n",
    "    return (images, labels)\n",
    "\n",
    "\n",
    "if not os.path.exists(\"/home/xilinx/jupyter_notebooks/bnn/test_32x32.mat\"):\n",
    "    !wget http://ufldl.stanford.edu/housenumbers/test_32x32.mat\n",
    "\n",
    "svhn_files, svhn_labels = load_svhn_testset(\"/home/xilinx/jupyter_notebooks/bnn/test_32x32.mat\", 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-02-25 11:45:11--  http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Resolving yann.lecun.com (yann.lecun.com)... failed: Temporary failure in name resolution.\n",
      "wget: unable to resolve host address ‘yann.lecun.com’\n",
      "--2020-02-25 11:45:12--  http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Resolving yann.lecun.com (yann.lecun.com)... failed: Temporary failure in name resolution.\n",
      "wget: unable to resolve host address ‘yann.lecun.com’\n"
     ]
    }
   ],
   "source": [
    "def load_mnist_testset(folder, num_images=10000):\n",
    "    num_images = min(num_images, 10000)\n",
    "\n",
    "    idx3_path = folder + \"/t10k-images-idx3-ubyte\"\n",
    "    idx1_path = folder + \"/t10k-labels-idx1-ubyte\"\n",
    "    labels = []\n",
    "    \n",
    "    with open(idx1_path, \"rb\") as lbl_file:\n",
    "        #read magic number and number of labels (MSB first) -> MNIST header\n",
    "        magicNum = int.from_bytes(lbl_file.read(4), byteorder=\"big\")\n",
    "        countLbl = int.from_bytes(lbl_file.read(4), byteorder=\"big\")\n",
    "        #now the labels are following byte-wise\n",
    "        for idx in range(num_images):\n",
    "            labels.append(int.from_bytes(lbl_file.read(1), byteorder=\"big\"))\n",
    "        lbl_file.close()\n",
    "\n",
    "    return (idx3_path, labels)\n",
    "    \n",
    "if not os.path.exists(\"/home/xilinx/jupyter_notebooks/bnn/t10k-images-idx3-ubyte.gz\"):\n",
    "    !wget http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz \n",
    "    !wget http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz \n",
    "        \n",
    "if not os.path.exists(\"/home/xilinx/jupyter_notebooks/bnn/t10k-images-idx3-ubyte\"):\n",
    "    !gzip -d t10k-images-idx3-ubyte.gz\n",
    "    !gzip -d t10k-labels-idx1-ubyte.gz\n",
    "\n",
    "mnist_files, mnist_labels = load_mnist_testset(\"/home/xilinx/jupyter_notebooks/bnn/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Start Xlnk Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "xlnk = Xlnk()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Define Utility Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Various functions for handling dictionaries and calculating statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(results, labels):\n",
    "    countRight = 0\n",
    "    for idx in range(len(labels)):\n",
    "        if labels[idx] == results[idx]:\n",
    "            countRight += 1\n",
    "    return countRight*100/len(labels)\n",
    "\n",
    "\n",
    "# Merge dictionaries that contain sub-dictionaries\n",
    "def dict_of_dicts_merge(*dicts):\n",
    "    out = {}\n",
    "    for item in dicts:\n",
    "        overlapping_keys = out.keys() & item.keys()\n",
    "        for key in overlapping_keys:\n",
    "            if (isinstance(out[key], dict) and isinstance(item[key], dict)):\n",
    "                out[key] = dict_of_dicts_merge(out[key], item[key])\n",
    "        for key in item.keys() - overlapping_keys:\n",
    "            out[key] = deepcopy(item[key])\n",
    "    return out\n",
    "\n",
    "\n",
    "def dict_to_str(dict):\n",
    "    dict_string = dumps(dict)\n",
    "    formatted_code, _ = FormatCode(dict_string)\n",
    "    return formatted_code\n",
    "\n",
    "\n",
    "def write_dict_to_file(file_name, output_dict):\n",
    "    os.makedirs(os.path.dirname(file_name), exist_ok=True)\n",
    "    f = open(file_name, \"w+\")\n",
    "    f.write(dict_to_str(output_dict))\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "## 5. A Simple Fault Test Example\n",
    "This example demonstrates the most simple method of running a fault test, and demonstrates the use of all of the classification function arguments. The classes beyond this section expand on this concept and allow the user to more easily set up customizeable and comprehensive tests.\n",
    "\n",
    "The test is performed in a way very simlar to how a normal image classification is performed. The main difference is that `classifier.classify_cifars_with_faults()` is called instead of `classifier.classify_cifars()`. This function takes additional arguments that specify the type, location, and number of faults.\n",
    "\n",
    "For the CnvClassifier, non-CIFAR10 datasets (e.g. GTSRB and SVHN) will need to be converted to CIFAR-10 format before being classified. This will be automatically handled by using the `classifier.classify_images()` function instead of `classifier.classify_cifars()`. This function takes a list of Pillow Images and converts them to the required format before classifying. For fault injection with these datasets, use `classifier.classify_images_with_faults()`.\n",
    "\n",
    "The inference can be performed with different precision for weights and activation. Creating a specific Classifier will automatically download the correct bitstream onto PL and load the weights and thresholds trained on the specific dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Availabe params: ['cifar10', 'road-signs', 'streetview']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/pynq/overlay.py:299: UserWarning: Users will not get PARAMETERS / REGISTERS information through TCL files. HWH file is recommended.\n",
      "  warnings.warn(message, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifying 1000 images with cnvW1A1-cifar10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/bnn/bnn.py:179: UserWarning: implicit cast from 'char *' to a different pointer type: will be forbidden in the future (check that the types are as you expect; use an explicit ffi.cast() if they are correct)\n",
      "  path.encode(), len(self.classes), size_ptr, usecperimage, num_faults, 1 if flip_word else 0, target_type, targets, len(target_layers)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference took 1582000.00 microseconds, 1582.00 usec per image\n",
      "Classification rate: 632.11 images per second\n",
      "Accuracy: 61.8\n"
     ]
    }
   ],
   "source": [
    "print(\"Availabe params:\", bnn.available_params(bnn.NETWORK_CNVW1A1))\n",
    "\n",
    "# Instantiate the cnvW1A1 hardware classifier with the CIFAR10 dataset\n",
    "classifier = bnn.CnvClassifier(bnn.NETWORK_CNVW1A1, 'cifar10', bnn.RUNTIME_HW)\n",
    "\n",
    "# Classify the dataset, and inject 10000 MBUs, targeting both weights and thresholds in the first 3 layers.\n",
    "#\n",
    "# The default value of target_layers is an empty list, which will target all layers.\n",
    "#\n",
    "# target_type determines if weights or thresholds will be targeted. A value of -1 causes both to be targeted, a value\n",
    "# of 0 causes weights to be targeted, and a value of 1 will target thresholds.\n",
    "print(\"Classifying\", len(cifar_labels), \"images with\", classifier.net + \"-\" + classifier.params)\n",
    "results = classifier.classify_cifars_with_faults(cifar_files, num_faults=10000, flip_word=True, target_type=-1, target_layers=[0, 1, 2])\n",
    "\n",
    "# Reset the device\n",
    "xlnk.xlnk_reset()\n",
    "\n",
    "# Calculate the accuracy of the network\n",
    "accuracy = calculate_accuracy(results, cifar_labels)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "\n",
    "## 6. Define Fault Testing Classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fault Test Class\n",
    "Uses the given network type and image set to run a series of fault tests on the network. The network is reset between runs.\n",
    "CNVFaultTest and LFCFaultTest provide class methods for easier instantiation of test with a specific classifier and dataset.\n",
    "\n",
    "**Constructor Arguments:**\n",
    "- **classifier_cls:** The classifier class type to use (e.g. bnn.CnvClassifier, bnn.LfcClassifier)\n",
    "- **network:** The network to test. e.g. bnn.NETWORK_CNVW1A1\n",
    "- **dataset:** The dataset that's being tested. (`'cifar10'`, `'streetview'`, or `'road-signs'`)\n",
    "- **input_file:** The file, or list of Images for non-cifar tests, containing the images to be tested.\n",
    "- **labels:** The list of ground truth labels for calculating accuracy.\n",
    "- **control_accuracy:** Optional parameter specifying the control accuracy of the network. Will be calculated if not provided.\n",
    "\n",
    "**FaultTest.run_test() Arguments:**\n",
    "- **num_runs:** The number of tests to perform\n",
    "- **num_flips:** The number of faults to inject per run\n",
    "- **flip_word:** A boolean indicating if a bit or word should be flipped\n",
    "- **weight_or_threshold:** An integer specifying if weights, thresholds, or both should be targeted. Obtain these values using the static methods in the TargetType class for clarity.\n",
    "\n",
    "        -1 = target weights and thresholds\n",
    "        0  = target weights only\n",
    "        1  = target thresholds only\n",
    "\n",
    "- **target_layers:** An array of integers specifying which layers to target. Leave empty to target all layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TargetType:\n",
    "    @staticmethod\n",
    "    def any():\n",
    "        return -1\n",
    "\n",
    "    @staticmethod\n",
    "    def weights():\n",
    "        return 0\n",
    "\n",
    "    @staticmethod\n",
    "    def thresholds():\n",
    "        return 1\n",
    "\n",
    "\n",
    "class FaultTest:\n",
    "    def __init__(self, classifier_cls, network, dataset, input_file, labels):\n",
    "        self.classifier_cls = classifier_cls\n",
    "        self.network = network\n",
    "        self.dataset = dataset\n",
    "        self.input_file = input_file\n",
    "        self.labels = labels\n",
    "    \n",
    "    def run_test(self, num_runs, num_flips, flip_word=False, target_type=TargetType.any(), target_layers=[]):\n",
    "        results    = [ None for i in range(num_runs) ]\n",
    "        times      = [ None for i in range(num_runs) ]\n",
    "        accuracies = [ None for i in range(num_runs) ]\n",
    "\n",
    "        for i in range(num_runs):\n",
    "            classifier = self.classifier_cls(self.network, self.dataset, bnn.RUNTIME_HW)\n",
    "\n",
    "            message = \"{}-{} run {} of {} (flipping {}{} {}(s) in {})\".format(\n",
    "                self.network,\n",
    "                self.dataset,\n",
    "                i+1,\n",
    "                num_runs,\n",
    "                num_flips,\n",
    "                ' weight' if target_type == 0 else ' threshold' if target_type == 1 else '',\n",
    "                'word' if flip_word else 'bit',\n",
    "                'any layer' if len(target_layers) == 0 else 'layer(s) {}'.format(target_layers)\n",
    "            )\n",
    "            print(message)\n",
    "\n",
    "            if self.dataset == 'cifar10':\n",
    "                results[i] = classifier.classify_cifars_with_faults(self.input_file, num_flips, flip_word, target_type, target_layers).tolist()\n",
    "            elif self.dataset == 'mnist':\n",
    "                results[i] = classifier.classify_mnists_with_faults(self.input_file, num_flips, flip_word, target_type, target_layers).tolist()\n",
    "            else:\n",
    "                results[i] = classifier.classify_images_with_faults(self.input_file, num_flips, flip_word, target_type, target_layers).tolist()\n",
    "\n",
    "            times[i]      = classifier.usecPerImage\n",
    "            accuracies[i] = calculate_accuracy(results[i], self.labels)\n",
    "\n",
    "            print(\"Accuracy:\", accuracies[i])\n",
    "\n",
    "            xlnk.xlnk_reset()\n",
    "            print()\n",
    "\n",
    "        return (results, times, accuracies)\n",
    "\n",
    "\n",
    "class CNVFaultTest(FaultTest):\n",
    "    def __init__(self, network, dataset, input_file, labels):\n",
    "        super().__init__(bnn.CnvClassifier, network, dataset, input_file, labels)\n",
    "\n",
    "    @classmethod\n",
    "    def CIFARTest(cls, network, input_file, labels):\n",
    "        return cls(network, 'cifar10', input_file, labels)\n",
    "\n",
    "    @classmethod\n",
    "    def SVHNTest(cls, network, input_file, labels):\n",
    "        return cls(network, 'streetview', input_file, labels)\n",
    "\n",
    "    @classmethod\n",
    "    def GTSRBTest(cls, network, input_file, labels):\n",
    "        return cls(network, 'road-signs', input_file, labels)\n",
    "\n",
    "\n",
    "class LFCFaultTest(FaultTest):\n",
    "    def __init__(self, network, dataset, input_file, labels):\n",
    "        super().__init__(bnn.LfcClassifier, network, dataset, input_file, labels)\n",
    "\n",
    "    @classmethod\n",
    "    def MNISTTest(cls, network, input_file, labels):\n",
    "        return cls(network, 'mnist', input_file, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "\n",
    "### Network Test Class\n",
    "Takes a FaultTest object and use it to run a comprehensive series of tests on different combinations of targets and SEU/MBU\n",
    "\n",
    "**Constructor Arguments:**\n",
    "- **fault_test:** A FaultTest (or derived class) object\n",
    "- **output_folder:** The folder to store the test results in. Results will be stored in subfolders organized by network and dataset.\n",
    "\n",
    "**NetworkTest.test_network() Arguments:**\n",
    "- **num_runs:** The number of runs in each test\n",
    "- **flip_counts:** A list of fault counts to inject each run. One test will be run for each.\n",
    "- **test_types:** A list of TestType objects which specify the location and type of fault for each test.\n",
    "- **target_layers:** An array of integers specifying which layers to target. Leave empty to target all layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestType:\n",
    "    def __init__(self, target_type, flip_word):\n",
    "        self.target_type = target_type\n",
    "        self.flip_word = flip_word\n",
    "        self.__build_name()\n",
    "\n",
    "    def __build_name(self):\n",
    "        self.name = ''\n",
    "\n",
    "        if self.target_type == TargetType.any():\n",
    "            self.name += 'any'\n",
    "        elif self.target_type == TargetType.weights():\n",
    "            self.name += 'weight'\n",
    "        else:\n",
    "            self.name += 'threshold'\n",
    "\n",
    "        self.name += ' '\n",
    "\n",
    "        if self.flip_word:\n",
    "            self.name += 'word'\n",
    "        else:\n",
    "            self.name += 'bit'\n",
    "\n",
    "    @classmethod\n",
    "    def any_bit(cls):\n",
    "        return cls(TargetType.any(), False)\n",
    "\n",
    "    @classmethod\n",
    "    def any_word(cls):\n",
    "        return cls(TargetType.any(), True)\n",
    "\n",
    "    @classmethod\n",
    "    def weight_bit(cls):\n",
    "        return cls(TargetType.weights(), False)\n",
    "\n",
    "    @classmethod\n",
    "    def weight_word(cls):\n",
    "        return cls(TargetType.weights(), True)\n",
    "\n",
    "    @classmethod\n",
    "    def threshold_bit(cls):\n",
    "        return cls(TargetType.thresholds(), False)\n",
    "\n",
    "    @classmethod\n",
    "    def threshold_word(cls):\n",
    "        return cls(TargetType.thresholds(), True)\n",
    "\n",
    "\n",
    "\n",
    "class NetworkTest:\n",
    "    def __init__(self, fault_test, output_folder):\n",
    "        self.fault_test = fault_test\n",
    "        self.output_folder = output_folder + '/' + self.fault_test.network + '/' + self.fault_test.dataset + '/'\n",
    "        self.control = None\n",
    "\n",
    "    def __run_control(self):\n",
    "        print(\"Running\", self.fault_test.network + \"-\" + self.fault_test.dataset, \"control test\")\n",
    "        _, _, accuracy = self.fault_test.run_test(num_runs=1, num_flips=0);\n",
    "        self.control = accuracy[0]\n",
    "\n",
    "    # Output dict contains the combined raw results from a test. Used as input to calculate_stats\n",
    "    def __build_output_dict(self, name, num_runs, num_flips, layers, accuracies):\n",
    "        out = {}\n",
    "        out[\"network\"] = self.fault_test.network\n",
    "        out[\"dataset\"] = self.fault_test.dataset\n",
    "        out[\"run count\"] = num_runs\n",
    "        out[\"flips\"] = num_flips\n",
    "        out[\"control\"] = self.control\n",
    "        out[\"layers\"] = layers\n",
    "        out[\"results\"] = {}\n",
    "        out[\"results\"][name] = accuracies\n",
    "        return out\n",
    "\n",
    "    # Calculates various stats given the results of a test (formatted with __build_output_dict)\n",
    "    def __calculate_stats(self, output_dict):\n",
    "        out = output_dict.copy()\n",
    "        for key, value in output_dict[\"results\"].items():\n",
    "            out[\"results\"][key] = {}\n",
    "            out[\"results\"][key][\"runs\"] = {}\n",
    "            out[\"results\"][key][\"runs\"][\"all\"] = value\n",
    "            out[\"results\"][key][\"runs\"][\"effective\"] = list(filter(lambda x: x != out[\"control\"], value))\n",
    "            out[\"results\"][key][\"effective count\"] = len(out[\"results\"][key][\"runs\"][\"effective\"])\n",
    "            out[\"results\"][key][\"min accuracy\"] = min(value)\n",
    "            out[\"results\"][key][\"max accuracy\"] = max(value)\n",
    "            if out[\"results\"][key][\"effective count\"] != 0:\n",
    "                out[\"results\"][key][\"avg accuracy\"] = sum(value) / len(value)\n",
    "                out[\"results\"][key][\"avg effective accuracy\"] = sum(out[\"results\"][key][\"runs\"][\"effective\"]) / out[\"results\"][key][\"effective count\"]\n",
    "                out[\"results\"][key][\"accuracy delta\"] = out[\"control\"] - out[\"results\"][key][\"avg accuracy\"]\n",
    "                out[\"results\"][key][\"effective accuracy delta\"] = out[\"control\"] - out[\"results\"][key][\"avg effective accuracy\"]\n",
    "            else:\n",
    "                out[\"results\"][key][\"avg accuracy\"] = out[\"control\"]\n",
    "        return out\n",
    "\n",
    "\n",
    "    def __run_tests(self, folder, num_runs, num_flips, test_types, target_layers):\n",
    "        output_dicts = []\n",
    "\n",
    "        for test in test_types:\n",
    "            _, _, accuracies = self.fault_test.run_test(num_runs, num_flips, test.flip_word, test.target_type, target_layers)\n",
    "            output = self.__build_output_dict(test.name, num_runs, num_flips, target_layers, accuracies)\n",
    "            output_dicts.append(output)\n",
    "            write_dict_to_file(folder + '/temp/' + self.fault_test.network + '_results' + test.name + '.json', output)\n",
    "\n",
    "        # Calculate stats\n",
    "        stats = dict_of_dicts_merge(*output_dicts)\n",
    "        stats = self.__calculate_stats(stats)\n",
    "        return stats\n",
    "\n",
    "        \n",
    "    def test_network(self, num_runs, flip_counts, test_types, target_layers=[]):\n",
    "        # Calculate the control accuracy\n",
    "        if self.control is None:\n",
    "            self.__run_control()\n",
    "\n",
    "        for num_flips in flip_counts:\n",
    "            folder = self.output_folder + '/' + str(num_flips) + 'flips/'\n",
    "\n",
    "            # Run all tests for this flip count\n",
    "            stats = self.__run_tests(folder, num_runs, num_flips, test_types, target_layers)\n",
    "\n",
    "            # Build file name\n",
    "            filename = folder + '/' + self.fault_test.network + '_' + self.fault_test.dataset\n",
    "            if len(target_layers) > 0:\n",
    "                filename = filename + \"_stats_layer{}.json\".format(target_layers)\n",
    "            else:\n",
    "                filename = filename + \"_stats.json\"\n",
    "\n",
    "            # Write results to the output file\n",
    "            write_dict_to_file(filename, stats)\n",
    "\n",
    "\n",
    "    def comprehensive_test(self, num_runs, flip_counts, target_layers=[]):\n",
    "        test_types = [\n",
    "            TestType.any_bit(), TestType.any_word(),\n",
    "            TestType.weight_bit(), TestType.weight_word(),\n",
    "            TestType.threshold_bit(), TestType.threshold_word()\n",
    "        ]\n",
    "\n",
    "        self.test_network(num_runs, flip_counts, test_types, target_layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "\n",
    "## 7. Run the tests\n",
    "The dictionary below instantiates tests for all of the available CNV networks. These tests are then conducted for each individual layer multiple times, with an increasing number of faults each time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_folder = \"/home/xilinx/jupyter_notebooks/bnn/faults/\"\n",
    "\n",
    "num_runs = 50\n",
    "flip_counts = [5, 10, 50, 100]\n",
    "\n",
    "cnv_tests = {\n",
    "    # cnvW1A1 Networks\n",
    "    'cnvW1A1': [\n",
    "#        NetworkTest(CNVFaultTest.CIFARTest(bnn.NETWORK_CNVW1A1, cifar_files, cifar_labels), output_folder),\n",
    "#        NetworkTest(CNVFaultTest.SVHNTest(bnn.NETWORK_CNVW1A1, svhn_files, svhn_labels), output_folder),\n",
    "#        NetworkTest(CNVFaultTest.GTSRBTest(bnn.NETWORK_CNVW1A1, gtsrb_files, gtsrb_labels), output_folder),\n",
    "    ],\n",
    "    'cnvW1A1-TMR': [\n",
    "#        NetworkTest(CNVFaultTest.CIFARTest(bnn.NETWORK_CNVW1A1_TMR, cifar_files, cifar_labels), output_folder),\n",
    "#        NetworkTest(CNVFaultTest.SVHNTest(bnn.NETWORK_CNVW1A1_TMR, svhn_files, svhn_labels), output_folder),\n",
    "#        NetworkTest(CNVFaultTest.GTSRBTest(bnn.NETWORK_CNVW1A1_TMR, gtsrb_files, gtsrb_labels), output_folder),\n",
    "    ],\n",
    "    'cnvW1A1-interleaved': [\n",
    "#        NetworkTest(CNVFaultTest.CIFARTest(bnn.NETWORK_CNVW1A1_INTERLEAVED, cifar_files, cifar_labels), output_folder),\n",
    "#        NetworkTest(CNVFaultTest.SVHNTest(bnn.NETWORK_CNVW1A1_INTERLEAVED, svhn_files, svhn_labels), output_folder),\n",
    "#        NetworkTest(CNVFaultTest.GTSRBTest(bnn.NETWORK_CNVW1A1_INTERLEAVED, gtsrb_files, gtsrb_labels), output_folder),\n",
    "    ],\n",
    "\n",
    "    # cnvW1A2 Networks\n",
    "    'cnvW1A2': [\n",
    "#        NetworkTest(CNVFaultTest.CIFARTest(bnn.NETWORK_CNVW1A2, cifar_files, cifar_labels), output_folder)\n",
    "    ],\n",
    "    'cnvW1A2-TMR': [\n",
    "#        NetworkTest(CNVFaultTest.CIFARTest(bnn.NETWORK_CNVW1A2_TMR, cifar_files, cifar_labels), output_folder)\n",
    "    ],\n",
    "    'cnvW1A2-interleaved': [\n",
    "        NetworkTest(CNVFaultTest.CIFARTest(bnn.NETWORK_CNVW1A2_INTERLEAVED, cifar_files, cifar_labels), output_folder)\n",
    "    ],\n",
    "\n",
    "    # cnvW2A2 Networks\n",
    "    'cnvW2A2': [\n",
    "#        NetworkTest(CNVFaultTest.CIFARTest(bnn.NETWORK_CNVW2A2, cifar_files, cifar_labels), output_folder)\n",
    "    ],\n",
    "    'cnvW2A2-TMR': [\n",
    "#        NetworkTest(CNVFaultTest.CIFARTest(bnn.NETWORK_CNVW2A2_TMR, cifar_files, cifar_labels), output_folder)\n",
    "    ],\n",
    "    'cnvW2A2-interleaved': [\n",
    "        NetworkTest(CNVFaultTest.CIFARTest(bnn.NETWORK_CNVW2A2_INTERLEAVED, cifar_files, cifar_labels), output_folder)\n",
    "    ],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_types = [TestType.weight_bit(), TestType.weight_word(), TestType.threshold_bit(), TestType.threshold_word()]\n",
    "only_weights = [TestType.weight_bit(), TestType.weight_word()]\n",
    "\n",
    "all_tests_flat = [test for lst in cnv_tests.values() for test in lst]\n",
    "\n",
    "for test in all_tests_flat:\n",
    "    test.test_network(num_runs, flip_counts, test_types=all_types, target_layers=[])"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
