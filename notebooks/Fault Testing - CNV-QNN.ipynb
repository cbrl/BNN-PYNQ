{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fault Injection on Quantized Neural Networks\n",
    "\n",
    "This notebook tests fault injection on quantized neural networks modified to mitigate the impact of faults.\n",
    "\n",
    "The different precision neural networks inspired at VGG-16 feature 6 convolutional layers, 3 max pool layers and 3 fully connected layers. The networks classify the CIFAR-10 testset. The 2 different precision networks tested here are:\n",
    "\n",
    "- CNVW1A1 using 1 bit weights and 1 bit activation,\n",
    "- CNVW1A2 using 1 bit weights and 2 bit activation,\n",
    "- CNVW2A2 using 2 bit weights and 2 bit activation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import the packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bnn\n",
    "import os\n",
    "import csv\n",
    "from copy import deepcopy\n",
    "from json import dumps\n",
    "from PIL import Image\n",
    "from yapf.yapflib.yapf_api import FormatCode\n",
    "import scipy.io as sio\n",
    "import matplotlib.pyplot as plt\n",
    "from pynq import Xlnk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load the required datasets\n",
    "\n",
    "This notebook requires the CIFAR-10, GTSRB, and SVHN datasets. You can download them from each given url via wget and unzip it to a folder on Pynq as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cifar10_testset(path):\n",
    "    if not os.path.exists(path + \"/test_batch_1000.bin\"):\n",
    "        with open(path + \"/test_batch.bin\", \"rb\") as infile:\n",
    "            with open(path + \"/test_batch_1000.bin\", \"wb+\") as outfile:\n",
    "                for i in range(1000):\n",
    "                    outfile.write(infile.read(3073))\n",
    "\n",
    "    labels = []\n",
    "    input_file = path + \"test_batch_1000.bin\"\n",
    "    with open(input_file, \"rb\") as file:\n",
    "        #for 10000 pictures\n",
    "        for i in range(1000):\n",
    "            #read first byte -> label\n",
    "            labels.append(int.from_bytes(file.read(1), byteorder=\"big\"))\n",
    "            #read image (3072 bytes) and do nothing with it\n",
    "            file.read(3072)\n",
    "        file.close()\n",
    "\n",
    "    print(\"Read\", len(labels), \"labels\")\n",
    "    return (input_file, labels)\n",
    "\n",
    "\n",
    "if not os.path.exists(\"/home/xilinx/jupyter_notebooks/bnn/cifar-10-binary.tar.gz\"):\n",
    "    #get\n",
    "    !wget https://www.cs.toronto.edu/~kriz/cifar-10-binary.tar.gz\n",
    "\n",
    "if not os.path.exists(\"/home/xilinx/jupyter_notebooks/bnn/cifar-10-batches-bin/\"):\n",
    "    #unzip\n",
    "    !tar -xf cifar-10-binary.tar.gz\n",
    "\n",
    "cifar_files, cifar_labels = load_cifar10_testset(\"/home/xilinx/jupyter_notebooks/bnn/cifar-10-batches-bin/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_gtsrb_testset(path):\n",
    "    image_files = []\n",
    "    images = []\n",
    "    labels = []\n",
    "\n",
    "    with open(path + \"/GT-final_test.csv\") as gtfile:\n",
    "        gtreader = csv.reader(gtfile, delimiter=';')\n",
    "        next(gtreader)\n",
    "        for row in gtreader:\n",
    "            image_files.append(path + '/' + row[0])\n",
    "            labels.append(int(row[7]))\n",
    "\n",
    "    labels = labels[0:1000]\n",
    "    for i in range(1000):\n",
    "        images.append(Image.open(image_files[i]))\n",
    "        images[i].load()\n",
    "\n",
    "    return (images, labels)\n",
    "\n",
    "\n",
    "if not os.path.exists(\"/home/xilinx/jupyter_notebooks/bnn/GTSRB_Final_Test_Images.zip\"):\n",
    "    !wget https://sid.erda.dk/public/archives/daaeac0d7ce1152aea9b61d9f1e19370/GTSRB_Final_Test_Images.zip\n",
    "\n",
    "if not os.path.exists(\"/home/xilinx/jupyter_notebooks/bnn/GTSRB_Final_Test_GT.zip\"):\n",
    "    !wget https://sid.erda.dk/public/archives/daaeac0d7ce1152aea9b61d9f1e19370/GTSRB_Final_Test_GT.zip\n",
    "\n",
    "if not os.path.exists(\"/home/xilinx/jupyter_notebooks/bnn/GTSRB\"):\n",
    "    !unzip -q -o GTSRB_Final_Test_Images.zip\n",
    "    !unzip -q -o GTSRB_Final_Test_GT.zip\n",
    "    !mv GT-final_test.csv GTSRB/Final_Test/Images\n",
    "\n",
    "gtsrb_files, gtsrb_labels = load_gtsrb_testset(\"/home/xilinx/jupyter_notebooks/bnn/GTSRB/Final_Test/Images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_svhn_testset(path):\n",
    "    images = []\n",
    "    labels = []\n",
    "\n",
    "    data = sio.loadmat(path)\n",
    "\n",
    "    # Subtact 1 to match classifier output. E.g. The classifier will return class 1 for an image of the number 2.\n",
    "    label_mat = data['y'] - 1\n",
    "    image_mat = data['X']\n",
    "\n",
    "    labels = label_mat.transpose().tolist()[0]\n",
    "    labels = labels[0:1000]\n",
    "\n",
    "    #for i in range(image_mat.shape[3]):\n",
    "    for i in range(1000):\n",
    "        images.append(Image.fromarray(image_mat[:,:,:,i]))\n",
    "        images[i].load()\n",
    "\n",
    "    return (images, labels)\n",
    "\n",
    "\n",
    "if not os.path.exists(\"/home/xilinx/jupyter_notebooks/bnn/test_32x32.mat\"):\n",
    "    !wget http://ufldl.stanford.edu/housenumbers/test_32x32.mat\n",
    "\n",
    "svhn_files, svhn_labels = load_svhn_testset(\"/home/xilinx/jupyter_notebooks/bnn/test_32x32.mat\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "## 3. Start Xlnk Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xlnk = Xlnk()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "## 4. A Simple Fault Test Example\n",
    "This example demonstrates the most simple method of running a fault test, and demonstrates the use of all of the classification function arguments. The classes beyond this section expand on this concept and allow the user to more easily set up customizeable and comprehensive tests.\n",
    "\n",
    "Non-CIFAR10 datasets (e.g. GTSRB and SVHN) will need to be converted to CIFAR-10 format before being classified. This will be automatically handled by using the `CnvClassifier.classify_images()` function instead of `CnvClassifier.classify_cifars()`. This function takes a list of Pillow Images and converts them to the required format before classifying. For fault injection, use `CnvClassifier.classify_images_with_faults()`.\n",
    "\n",
    "The inference can be performed with different precision for weights and activation. Creating a specific Classifier will automatically download the correct bitstream onto PL and load the weights and thresholds trained on the specific dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Availabe params:\", bnn.available_params(bnn.NETWORK_CNVW1A1))\n",
    "\n",
    "# Instantiate the cnvW1A1 hardware classifier with the CIFAR-10 dataset\n",
    "classifier = bnn.CnvClassifier(bnn.NETWORK_CNVW1A1, 'cifar10', bnn.RUNTIME_HW)\n",
    "\n",
    "# Classify the dataset, and inject 10000 MBUs, targeting both weights and thresholds in the first 3 layers.\n",
    "#\n",
    "# The default value of target_layers is an empty list, which will target all layers.\n",
    "#\n",
    "# target_type determines if weights or thresholds will be targeted. A value of -1 causes both to be targeted, a value\n",
    "# of 0 causes weights to be targeted, and a value of 1 will target thresholds.\n",
    "print(\"Classifying\", len(cifar_labels), \"images with\", classifier.net + \"-\" + classifier.params)\n",
    "results = classifier.classify_cifars_with_faults(cifar_files, num_faults=10000, flip_word=True, target_type=-1, target_layers=[0, 1, 2])\n",
    "\n",
    "# Reset the device\n",
    "xlnk.xlnk_reset()\n",
    "\n",
    "# Calculate the accuracy of the network\n",
    "countRight = 0\n",
    "for i in range(len(cifar_labels)):\n",
    "    if labels[i] == results[i]:\n",
    "        countRight += 1\n",
    "accuracy = (countRight * 100) / len(labels)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "## 5. Define Utility Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Various functions for handling dictionaries and calculating statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(results, labels):\n",
    "    countRight = 0\n",
    "    for idx in range(len(labels)):\n",
    "        if labels[idx] == results[idx]:\n",
    "            countRight += 1\n",
    "    return countRight*100/len(labels)\n",
    "\n",
    "\n",
    "#Merge dictionaries that contain sub-dictionaries\n",
    "def dict_of_dicts_merge(*dicts):\n",
    "    out = {}\n",
    "    for item in dicts:\n",
    "        overlapping_keys = out.keys() & item.keys()\n",
    "        for key in overlapping_keys:\n",
    "            if (isinstance(out[key], dict) and isinstance(item[key], dict)):\n",
    "                out[key] = dict_of_dicts_merge(out[key], item[key])\n",
    "        for key in item.keys() - overlapping_keys:\n",
    "            out[key] = deepcopy(item[key])\n",
    "    return out\n",
    "\n",
    "\n",
    "#Output dict contains the combined raw results from a test. Used as input to calculate_stats\n",
    "def make_output_dict(network_name, dataset, num_runs, num_flips, accuracy_control, run_type, accuracies):\n",
    "    out = {}\n",
    "    out[\"network\"] = network_name\n",
    "    out[\"dataset\"] = dataset\n",
    "    out[\"run count\"] = num_runs\n",
    "    out[\"flips\"] = num_flips\n",
    "    out[\"control\"] = accuracy_control\n",
    "    out[\"results\"] = {}\n",
    "    out[\"results\"][run_type] = accuracies\n",
    "    return out\n",
    "\n",
    "\n",
    "#Calculates various stats given the results of a test (formatted with make_output_dict)\n",
    "def calculate_stats(output_dict):\n",
    "    out = output_dict.copy()\n",
    "    for key, value in output_dict[\"results\"].items():\n",
    "        out[\"results\"][key] = {}\n",
    "        out[\"results\"][key][\"runs\"] = {}\n",
    "        out[\"results\"][key][\"runs\"][\"all\"] = value\n",
    "        out[\"results\"][key][\"runs\"][\"effective\"] = list(filter(lambda x: x != out[\"control\"], value))\n",
    "        out[\"results\"][key][\"effective count\"] = len(out[\"results\"][key][\"runs\"][\"effective\"])\n",
    "        out[\"results\"][key][\"min accuracy\"] = min(value)\n",
    "        out[\"results\"][key][\"max accuracy\"] = max(value)\n",
    "        if out[\"results\"][key][\"effective count\"] != 0:\n",
    "            out[\"results\"][key][\"avg accuracy\"] = sum(value) / len(value)\n",
    "            out[\"results\"][key][\"avg effective accuracy\"] = sum(out[\"results\"][key][\"runs\"][\"effective\"]) / out[\"results\"][key][\"effective count\"]\n",
    "            out[\"results\"][key][\"accuracy delta\"] = out[\"control\"] - out[\"results\"][key][\"avg accuracy\"]\n",
    "            out[\"results\"][key][\"effective accuracy delta\"] = out[\"control\"] - out[\"results\"][key][\"avg effective accuracy\"]\n",
    "        else:\n",
    "            out[\"results\"][key][\"avg accuracy\"] = out[\"control\"]\n",
    "    return out\n",
    "\n",
    "\n",
    "def dict_to_str(dict):\n",
    "    dict_string = dumps(dict)\n",
    "    formatted_code, _ = FormatCode(dict_string)\n",
    "    return formatted_code\n",
    "\n",
    "\n",
    "def write_stats_file(file_name, stats_dict):\n",
    "    os.makedirs(os.path.dirname(file_name), exist_ok=True)\n",
    "    f = open(file_name, \"w+\")\n",
    "    f.write(dict_to_str(stats_dict))\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "\n",
    "## 6. Define Fault Testing Classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fault Test Class\n",
    "Uses the given network type and image set to run a series of fault tests on the network. The network is reset between runs.\n",
    "\n",
    "**Constructor Arguments:**\n",
    "- **network:** The network to test. e.g. bnn.NETWORK_CNVW1A1\n",
    "- **dataset:** The dataset that's being tested. (`'cifar10'`, `'streetview'`, or `'road-signs'`)\n",
    "- **input_file:** The file, or list of Images for non-cifar tests, containing the images to be tested.\n",
    "- **labels:** The list of ground truth labels for calculating accuracy.\n",
    "- **control_accuracy:** Optional parameter specifying the control accuracy of the network. Will be calculated if not provided.\n",
    "\n",
    "**FaultTest.run_test() Arguments:**\n",
    "- **num_runs:** The number of tests to perform\n",
    "- **num_flips:** The number of faults to inject per run\n",
    "- **flip_word:** A boolean indicating if a bit or word should be flipped\n",
    "- **weight_or_threshold:** An integer specifying if weights, thresholds, or both should be targeted.\n",
    "\n",
    "        -1 = target weights and activations\n",
    "        0  = target weights only\n",
    "        1  = target activations only\n",
    "- **target_layers:** An array of integers specifying which layers to target. Leave empty to target all layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FaultTest:\n",
    "    def __init__(self, network, dataset, input_file, labels):\n",
    "        self.network = network\n",
    "        self.dataset = dataset\n",
    "        self.input_file = input_file\n",
    "        self.labels = labels\n",
    "\n",
    "    @classmethod\n",
    "    def CIFARTest(cls, network, input_file, labels):\n",
    "        return cls(network, 'cifar10', input_file, labels)\n",
    "\n",
    "    @classmethod\n",
    "    def SVHNTest(cls, network, input_file, labels):\n",
    "        return cls(network, 'streetview', input_file, labels)\n",
    "\n",
    "    @classmethod\n",
    "    def GTSRBTest(cls, network, input_file, labels):\n",
    "        return cls(network, 'road-signs', input_file, labels)\n",
    "    \n",
    "    def run_test(self, num_runs, num_flips, flip_word=False, weight_or_threshold=-1, target_layers = []):\n",
    "        results    = [ None for i in range(num_runs) ]\n",
    "        times      = [ None for i in range(num_runs) ]\n",
    "        accuracies = [ None for i in range(num_runs) ]\n",
    "\n",
    "        for i in range(num_runs):\n",
    "            hw_classifier = bnn.CnvClassifier(self.network, self.dataset, bnn.RUNTIME_HW)\n",
    "\n",
    "            message = \"{}-{} run {} of {}\".format(self.network, self.dataset, i+1, num_runs)\n",
    "            if len(target_layers) == 0:\n",
    "                message += \" (flipping {} {}(s) in any layer)\".format(num_flips, \"word\" if flip_word else \"bit\")\n",
    "            else:\n",
    "                message += \" (flipping {} {}(s) in layer(s) {})\".format(num_flips, \"word\" if flip_word else \"bit\", target_layers)\n",
    "            print(message)\n",
    "\n",
    "            if self.dataset == 'cifar10':\n",
    "                results[i] = hw_classifier.classify_cifars_with_faults(self.input_file, num_flips, flip_word, weight_or_threshold, target_layers)\n",
    "            else:\n",
    "                results[i] = hw_classifier.classify_images_with_faults(self.input_file, num_flips, flip_word, weight_or_threshold, target_layers)\n",
    "\n",
    "            times[i]      = hw_classifier.usecPerImage\n",
    "            accuracies[i] = calculate_accuracy(results[i], self.labels)\n",
    "\n",
    "            print(\"Accuracy:\", accuracies[i])\n",
    "\n",
    "            xlnk.xlnk_reset()\n",
    "            print()\n",
    "\n",
    "        return (results, times, accuracies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "\n",
    "### Network Test Class\n",
    "Takes a FaultTest object and use it to run a comprehensive series of tests on different combinations of targets and SEU/MBU\n",
    "\n",
    "**Constructor Arguments:**\n",
    "- **fault_test:** A FaultTest object\n",
    "- **output_folder:** The folder to store the test results in\n",
    "\n",
    "**NetworkTest.test_network() Arguments:**\n",
    "- **num_runs:** The number of times to run each test\n",
    "- **num_flips:** The number of faults to inject each run\n",
    "- **bit_flips:** Whether or not to run bit flip tests\n",
    "- **word_flips:** Whether or not to run word flip tests\n",
    "- **weights:** Whether or not to run tests targeting weights\n",
    "- **thresholds:** Whether or not to run tests targeting thresholds\n",
    "- **target_layers:** An array of integers specifying which layers to target. Leave empty to target all layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetworkTest:\n",
    "    def __init__(self, fault_test, output_folder):\n",
    "        self.fault_test = fault_test\n",
    "        self.output_folder = output_folder + '/' + self.fault_test.network + '/' + self.fault_test.dataset + '/'\n",
    "        self.control = -1\n",
    "\n",
    "\n",
    "    def __run_control(self):\n",
    "        _, _, accuracy = self.fault_test.run_test(num_runs=1, num_flips=0);\n",
    "        self.control = accuracy[0]\n",
    "\n",
    "\n",
    "    def __build_output_dict(self, name, num_runs, num_flips, accuracies):\n",
    "        return make_output_dict(\n",
    "            self.fault_test.network,\n",
    "            self.fault_test.dataset,\n",
    "            num_runs,\n",
    "            num_flips,\n",
    "            self.control,\n",
    "            name,\n",
    "            accuracies\n",
    "        )\n",
    "\n",
    "\n",
    "    def __run_tests(self, folder, num_runs, num_flips, bit_flips, word_flips, weights, thresholds, target_layers):\n",
    "        #Separate output dicts for each run. They will be combined later for the\n",
    "        #final results, and the redundant data will be discarded.\n",
    "        weight_bit_output = {}\n",
    "        threshold_bit_output = {}\n",
    "        weight_word_output = {}\n",
    "        threshold_word_output = {}\n",
    "        stats = {}\n",
    "\n",
    "        if bit_flips:\n",
    "            if weights: #Test bit flips (weights)\n",
    "                _, _, accuracies = self.fault_test.run_test(num_runs, num_flips, False, 0, target_layers)\n",
    "                \n",
    "                weight_bit_output = self.__build_output_dict(\"weight bit\", num_runs, num_flips, accuracies)\n",
    "\n",
    "                write_stats_file(folder + \"/temp/\" + self.fault_test.network + \"_results_bit_weight.json\", weight_bit_output)\n",
    "\n",
    "            if thresholds: #Test bit flips (thresholds)\n",
    "                _, _, accuracies = self.fault_test.run_test(num_runs, num_flips, False, 1, target_layers)\n",
    "                \n",
    "                threshold_bit_output = self.__build_output_dict(\"threshold bit\", num_runs, num_flips, accuracies)\n",
    "\n",
    "                write_stats_file(folder + \"/temp/\" + self.fault_test.network + \"_results_bit_threshold.json\", threshold_bit_output)\n",
    "\n",
    "        if word_flips:\n",
    "            if weights: #Test word flips (weights)\n",
    "                _, _, accuracies = self.fault_test.run_test(num_runs, num_flips, True, 0, target_layers)\n",
    "                \n",
    "                weight_word_output = self.__build_output_dict(\"weight word\", num_runs, num_flips, accuracies)\n",
    "\n",
    "                write_stats_file(folder + \"/temp/\" + self.fault_test.network + \"_results_word_weight.json\", weight_word_output)\n",
    "            \n",
    "            if thresholds: #Test word flips (thresholds)\n",
    "                _, _, accuracies = self.fault_test.run_test(num_runs, num_flips, True, 1, target_layers)\n",
    "                \n",
    "                threshold_word_output = self.__build_output_dict(\"threshold word\", num_runs, num_flips, accuracies)\n",
    "\n",
    "                write_stats_file(folder + \"/temp/\" + self.fault_test.network + \"_results_word_threshold.json\", threshold_word_output)\n",
    "\n",
    "        # Calculate stats\n",
    "        stats = dict_of_dicts_merge(weight_bit_output, threshold_bit_output, weight_word_output, threshold_word_output)\n",
    "        stats = calculate_stats(stats)\n",
    "        return stats\n",
    "\n",
    "\n",
    "    def test_network(self, num_runs, num_flips, bit_flips=True, word_flips=True, weights=True, thresholds=True, target_layers = []):\n",
    "        folder = self.output_folder + '/' + str(num_flips) + 'flips/'\n",
    "\n",
    "        # Calculate the control accuracy\n",
    "        if self.control < 0:\n",
    "            self.__run_control()\n",
    "\n",
    "        # Run all tests\n",
    "        stats = self.__run_tests(folder, num_runs, num_flips, bit_flips, word_flips, weights, thresholds, target_layers)\n",
    "\n",
    "        # Write all stats to the output file\n",
    "        filename = folder + '/' + self.fault_test.network + '_' + self.fault_test.dataset\n",
    "        if len(target_layers) > 0:\n",
    "            filename = filename + \"_stats_layer{}.json\".format(target_layers)\n",
    "        else:\n",
    "            filename = filename + \"_stats.json\"\n",
    "\n",
    "        write_stats_file(filename, stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "\n",
    "## 7. Run the tests\n",
    "The dictionary below instantiates tests for all of the available CNV networks. These tests are then conducted for each individual layer multiple times, with an increasing number of faults each time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_folder = \"/home/xilinx/jupyter_notebooks/bnn/faults/\"\n",
    "\n",
    "num_runs = 40\n",
    "flip_counts = [5, 10, 50, 100]\n",
    "\n",
    "tests = {\n",
    "    # cnvW1A1 Networks\n",
    "    'cnvW1A1': [\n",
    "        NetworkTest(FaultTest.CIFARTest(bnn.NETWORK_CNVW1A1, cifar_files, cifar_labels), output_folder),\n",
    "        NetworkTest(FaultTest.SVHNTest(bnn.NETWORK_CNVW1A1, svhn_files, svhn_labels), output_folder),\n",
    "        NetworkTest(FaultTest.GTSRBTest(bnn.NETWORK_CNVW1A1, gtsrb_files, gtsrb_labels), output_folder),\n",
    "    ],\n",
    "    'cnvW1A1-TMR': [\n",
    "        NetworkTest(FaultTest.CIFARTest(bnn.NETWORK_CNVW1A1_TMR, cifar_files, cifar_labels), output_folder),\n",
    "        NetworkTest(FaultTest.SVHNTest(bnn.NETWORK_CNVW1A1_TMR, svhn_files, svhn_labels), output_folder),\n",
    "        NetworkTest(FaultTest.GTSRBTest(bnn.NETWORK_CNVW1A1_TMR, gtsrb_files, gtsrb_labels), output_folder),\n",
    "    ],\n",
    "    'cnvW1A1-interleaved': [\n",
    "        NetworkTest(FaultTest.CIFARTest(bnn.NETWORK_CNVW1A1_INTERLEAVED, cifar_files, cifar_labels), output_folder),\n",
    "        NetworkTest(FaultTest.SVHNTest(bnn.NETWORK_CNVW1A1_INTERLEAVED, svhn_files, svhn_labels), output_folder),\n",
    "        NetworkTest(FaultTest.GTSRBTest(bnn.NETWORK_CNVW1A1_INTERLEAVED, gtsrb_files, gtsrb_labels), output_folder),\n",
    "    ],\n",
    "\n",
    "    # cnvW1A2 Networks\n",
    "    'cnvW1A2': [\n",
    "        NetworkTest(FaultTest.CIFARTest(bnn.NETWORK_CNVW1A2, cifar_files, cifar_labels), output_folder)\n",
    "    ],\n",
    "#    'cnvW1A2-TMR': [\n",
    "#        NetworkTest(FaultTest.CIFARTest(bnn.NETWORK_CNVW1A2_TMR, cifar_files, cifar_labels), output_folder)\n",
    "#    ],\n",
    "    'cnvW1A2-interleaved': [\n",
    "        NetworkTest(FaultTest.CIFARTest(bnn.NETWORK_CNVW1A2_INTERLEAVED, cifar_files, cifar_labels), output_folder)\n",
    "    ],\n",
    "\n",
    "    # cnvW2A2 Networks\n",
    "    'cnvW2A2': [\n",
    "        NetworkTest(FaultTest.CIFARTest(bnn.NETWORK_CNVW2A2, cifar_files, cifar_labels), output_folder)\n",
    "    ],\n",
    "    'cnvW2A2-TMR': [\n",
    "        NetworkTest(FaultTest.CIFARTest(bnn.NETWORK_CNVW2A2_TMR, cifar_files, cifar_labels), output_folder)\n",
    "    ],\n",
    "    'cnvW2A2-interleaved': [\n",
    "        NetworkTest(FaultTest.CIFARTest(bnn.NETWORK_CNVW2A2_INTERLEAVED, cifar_files, cifar_labels), output_folder)\n",
    "    ],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run all tests\n",
    "for layer in range(9):\n",
    "    for flips in flip_counts:\n",
    "        for key, test_array in tests.items():\n",
    "            for test in test_array:\n",
    "                test.test_network(num_runs, flips, bit_flips=True, word_flips=True, weights=True, thresholds=True, target_layers=[layer])"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
