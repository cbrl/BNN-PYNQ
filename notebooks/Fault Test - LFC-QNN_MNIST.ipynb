{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QNN on Pynq\n",
    "\n",
    "This notebook covers how to use low quantized Neural Networks on Pynq for inference on MNIST dataset by using LFC network composed of 4 fully connected layers with 1024 neurons each. There are 2 networks using different precision: \n",
    "\n",
    "- LFCW1A1 using 1 bit weights and 1 activation,\n",
    "- LFCW1A2 using 1 bit weights and 2 activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bnn\n",
    "import os\n",
    "from copy import deepcopy\n",
    "from json import dumps\n",
    "from yapf.yapflib.yapf_api import FormatCode\n",
    "import matplotlib.pyplot as plt\n",
    "from pynq import Xlnk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. LFC and MNIST\n",
    "\n",
    "This notebook performs inference on MNIST test set from http://yann.lecun.com/exdb/mnist/ which contains 10000 pictures of handwritten digits. The LFC network requires MNIST formatted input data, that's why the binary test file can be directly loaded. All other images have to be formatted to this specification (refer to url and LFC webcam examples).\n",
    "\n",
    "At first you need to download mnist test set and labels using wget and unzip the archive as shown below:\n",
    "In order to be able to compare the inferred classes against the expected labels we first read the labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"/home/xilinx/jupyter_notebooks/bnn/t10k-images-idx3-ubyte.gz\"):\n",
    "    #get\n",
    "    !wget http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz \n",
    "    !wget http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz \n",
    "        \n",
    "if not os.path.exists(\"/home/xilinx/jupyter_notebooks/bnn/t10k-images-idx3-ubyte\"):\n",
    "    #unzip    \n",
    "    !gzip -d t10k-images-idx3-ubyte.gz\n",
    "    !gzip -d t10k-labels-idx1-ubyte.gz\n",
    "\n",
    "#read labels\n",
    "labels = []\n",
    "with open(\"/home/xilinx/jupyter_notebooks/bnn/t10k-labels-idx1-ubyte\",\"rb\") as lbl_file:\n",
    "    #read magic number and number of labels (MSB first) -> MNIST header\n",
    "    magicNum = int.from_bytes(lbl_file.read(4), byteorder=\"big\")\n",
    "    countLbl = int.from_bytes(lbl_file.read(4), byteorder=\"big\")\n",
    "    #now the labels are following byte-wise\n",
    "    for idx in range(countLbl):\n",
    "        labels.append(int.from_bytes(lbl_file.read(1), byteorder=\"big\"))\n",
    "    lbl_file.close()\n",
    "len(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Hardware Inference\n",
    "\n",
    "First of all a classifier needs to be instantiated. Using the LfcClassifier will allow to classify MNIST formatted images utilizing LFC network. There are two different runtimes available: hardware accelerated and pure software environment.\n",
    "\n",
    "Once a classifier is instantiated the inference on MNIST images can be started using `classify_mnist` or `classify_mnists` methods - for both single and multiple images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xlnk = Xlnk()\n",
    "\n",
    "num_runs = 200\n",
    "input_file = \"/home/xilinx/jupyter_notebooks/bnn/t10k-images-idx3-ubyte\"\n",
    "output_folder = \"/home/xilinx/jupyter_notebooks/bnn/{}flips/lfc/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(results, labels):\n",
    "    countRight = 0\n",
    "    for idx in range(len(labels)):\n",
    "        if labels[idx] == results[idx]:\n",
    "            countRight += 1\n",
    "    return countRight*100/len(labels)\n",
    "\n",
    "\n",
    "#Merge dictionaries that contain sub-dictionaries\n",
    "def dict_of_dicts_merge(*dicts):\n",
    "    out = {}\n",
    "    for item in dicts:\n",
    "        overlapping_keys = out.keys() & item.keys()\n",
    "        for key in overlapping_keys:\n",
    "            if (isinstance(out[key], dict) and isinstance(item[key], dict)):\n",
    "                out[key] = dict_of_dicts_merge(out[key], item[key])\n",
    "        for key in item.keys() - overlapping_keys:\n",
    "            out[key] = deepcopy(item[key])\n",
    "    return out\n",
    "\n",
    "\n",
    "#Make a dictionary for storing the results, times, or accuracies from a test\n",
    "def make_results_dict(size, targeting_bits_and_words, targeting_weights_and_activations):\n",
    "    if targeting_bits_and_words and targeting_weights_and_activations:\n",
    "        return {\n",
    "            \"bit\": {\n",
    "                \"weight\": [ None for i in range(size) ],\n",
    "                \"activation\": [ None for i in range(size) ],\n",
    "            },\n",
    "            \"word\": {\n",
    "                \"weight\": [ None for i in range(size) ],\n",
    "                \"activation\": [ None for i in range(numsize_runs) ],\n",
    "            },\n",
    "        }\n",
    "    elif targeting_bits_and_words:\n",
    "        return {\n",
    "            \"bit\": [ None for i in range(size) ],\n",
    "            \"word\": [ None for i in range(size) ],\n",
    "        }\n",
    "    elif targeting_weights_and_activations:\n",
    "        return {\n",
    "            \"weight\": [ None for i in range(size) ],\n",
    "            \"activation\": [ None for i in range(numsize_runs) ],\n",
    "        }\n",
    "\n",
    "\n",
    "#Output dict contains the combined raw results from a test. Used as input to calculate_stats\n",
    "def make_output_dict(network_name, num_runs, num_flips, accuracy_control, accuracies_dict):\n",
    "    out = {}\n",
    "    out[\"network\"] = network_name\n",
    "    out[\"run count\"] = num_runs\n",
    "    out[\"flips\"] = num_flips\n",
    "    out[\"control\"] = accuracy_control\n",
    "    out[\"results\"] = {}\n",
    "    for key, val in accuracies_dict.items():\n",
    "        out[\"results\"][key] = val\n",
    "    return out\n",
    "\n",
    "\n",
    "#Calculates various stats given the results of a test (formatted with make_output_dict)\n",
    "def calculate_stats(output_dict):\n",
    "    out = output_dict.copy()\n",
    "    for key, value in output_dict[\"results\"].items():\n",
    "        out[\"results\"][key] = {}\n",
    "        out[\"results\"][key][\"runs\"] = {}\n",
    "        out[\"results\"][key][\"runs\"][\"all\"] = value\n",
    "        out[\"results\"][key][\"runs\"][\"effective\"] = list(filter(lambda x: x != out[\"control\"], value))\n",
    "        out[\"results\"][key][\"effective count\"] = len(out[\"results\"][key][\"runs\"][\"effective\"])\n",
    "        if out[\"results\"][key][\"effective count\"] != 0:\n",
    "            out[\"results\"][key][\"avg accuracy\"] = sum(value) / len(value)\n",
    "            out[\"results\"][key][\"avg effective accuracy\"] = sum(out[\"results\"][key][\"runs\"][\"effective\"]) / out[\"results\"][key][\"effective count\"]\n",
    "            out[\"results\"][key][\"effective accuracy delta\"] = out[\"control\"] - out[\"results\"][key][\"avg effective accuracy\"]\n",
    "        out[\"results\"][key][\"min accuracy\"] = min(value)\n",
    "        out[\"results\"][key][\"max accuracy\"] = max(value)\n",
    "    return out\n",
    "\n",
    "\n",
    "def dict_to_str(dict):\n",
    "    dict_string = dumps(dict)\n",
    "    formatted_code, _ = FormatCode(dict_string)\n",
    "    return formatted_code\n",
    "\n",
    "\n",
    "def write_stats_file(file_name, stats_dict):\n",
    "    os.makedirs(os.path.dirname(file_name), exist_ok=True)\n",
    "    f = open(file_name, \"w+\")\n",
    "    f.write(dict_to_str(stats_dict))\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fault Test Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lfc_mnist_fault_test(title, network, input_file, num_runs, num_flips, flip_word, weight_or_activation, target_layers = []):\n",
    "    results    = [ None for i in range(num_runs) ]\n",
    "    times      = [ None for i in range(num_runs) ]\n",
    "    accuracies = [ None for i in range(num_runs) ]\n",
    "\n",
    "    for i in range(num_runs):\n",
    "        hw_classifier = bnn.LfcClassifier(network, 'mnist', bnn.RUNTIME_HW)\n",
    "        print(\"{} run {} of {} (flipping {} {}(s) at random times)\".format(title, i+1, num_runs, num_flips, \"word\" if flip_word else \"bit\"))\n",
    "\n",
    "        results[i]    = hw_classifier.classify_mnists_with_faults(input_file, num_flips, flip_word, weight_or_activation, target_layers)\n",
    "        times[i]      = hw_classifier.usecPerImage\n",
    "        accuracies[i] = calculate_accuracy(results[i], labels)\n",
    "\n",
    "        print(\"Accuracy:\", accuracies[i])\n",
    "\n",
    "        xlnk.xlnk_reset()\n",
    "        print()\n",
    "    \n",
    "    return (results, times, accuracies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### W1A1 - 1 bit weights and 1 bit activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Control run\n",
    "accuracy_W1A1_control = 0\n",
    "result_W1A1_control = None\n",
    "time_W1A1_control = 0\n",
    "\n",
    "#Control test\n",
    "hw_classifier = bnn.LfcClassifier(bnn.NETWORK_LFCW1A1, \"mnist\", bnn.RUNTIME_HW)\n",
    "\n",
    "print(\"Control classification\")\n",
    "result_W1A1_control   = hw_classifier.classify_mnists(input_file)\n",
    "time_W1A1_control     = hw_classifier.usecPerImage\n",
    "accuracy_W1A1_control = calculate_accuracy(result_W1A1_control, labels)\n",
    "print(\"Accuracy:\", accuracy_W1A1_control)\n",
    "\n",
    "#Reset the device\n",
    "xlnk.xlnk_reset()\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_W1A1(num_runs, num_flips, output_folder):\n",
    "    weight_bit_output = {}\n",
    "    activation_bit_output = {}\n",
    "    weight_word_output = {}\n",
    "    activation_word_output = {}\n",
    "    stats = {}\n",
    "\n",
    "    #Test bit flips (weight)\n",
    "    weight_bit_data   = lfc_mnist_fault_test(\"Weight Bit\", bnn.NETWORK_LFCW1A1, input_file, num_runs, num_flips, False, 0)\n",
    "    weight_bit_output = make_output_dict(\"lfcW1A1\", num_runs, num_flips, accuracy_W1A1_control, {\"weight bit\": weight_bit_data[2]})\n",
    "\n",
    "    write_stats_file(output_folder.format(num_flips) + \"temp/lfcW1A1_results_bit_weight.txt\", weight_bit_output)\n",
    "\n",
    "\n",
    "    #Test bit flips (activation)\n",
    "    activation_bit_data   = lfc_mnist_fault_test(\"Activation Bit\", bnn.NETWORK_LFCW1A1, input_file, num_runs, num_flips, False, 1)\n",
    "    activation_bit_output = make_output_dict(\"lfcW1A1\", num_runs, num_flips, accuracy_W1A1_control, {\"activation bit\": activation_bit_data[2]})\n",
    "\n",
    "    write_stats_file(output_folder.format(num_flips) + \"temp/lfcW1A1_results_bit_activation.txt\", activation_bit_output)\n",
    "\n",
    "\n",
    "    #Test word flips (weight)\n",
    "    weight_word_data   = lfc_mnist_fault_test(\"Weight Word\", bnn.NETWORK_LFCW1A1, input_file, num_runs, num_flips, True, 0)\n",
    "    weight_word_output = make_output_dict(\"lfcW1A1\", num_runs, num_flips, accuracy_W1A1_control, {\"weight word\": weight_word_data[2]})\n",
    "\n",
    "    write_stats_file(output_folder.format(num_flips) + \"temp/lfcW1A1_results_word_weight.txt\", weight_word_output)\n",
    "\n",
    "\n",
    "    #Test word flips (activation)\n",
    "    activation_word_data   = lfc_mnist_fault_test(\"Activation Word\", bnn.NETWORK_LFCW1A1, input_file, num_runs, num_flips, True, 1)\n",
    "    activation_word_output = make_output_dict(\"lfcW1A1\", num_runs, num_flips, accuracy_W1A1_control, {\"activation word\": activation_word_data[2]})\n",
    "\n",
    "    write_stats_file(output_folder.format(num_flips) + \"temp/lfcW1A1_results_word_activation.txt\", activation_word_output)\n",
    "\n",
    "\n",
    "    #Write all stats to file\n",
    "    stats = dict_of_dicts_merge(weight_bit_output, activation_bit_output, weight_word_output, activation_word_output)\n",
    "    stats = calculate_stats(stats)\n",
    "    write_stats_file(output_folder.format(num_flips) + \"lfcW1A1_stats.txt\", stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### W1A2 - 1 bit weights and 2 bit activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Control run\n",
    "accuracy_W1A2_control = 0\n",
    "result_W1A2_control = None\n",
    "time_W1A2_control = 0\n",
    "\n",
    "#Control test\n",
    "hw_classifier = bnn.LfcClassifier(bnn.NETWORK_LFCW1A2, \"mnist\", bnn.RUNTIME_HW)\n",
    "\n",
    "print(\"Control classification\")\n",
    "result_W1A2_control  = hw_classifier.classify_mnists(input_file)\n",
    "time_W1A2_control     = hw_classifier.usecPerImage\n",
    "accuracy_W1A2_control = calculate_accuracy(result_W1A2_control, labels)\n",
    "print(\"Accuracy:\", accuracy_W1A1_control)\n",
    "\n",
    "#Reset the device\n",
    "xlnk.xlnk_reset()\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_W1A2(num_runs, num_flips, output_folder):\n",
    "    weight_bit_output = {}\n",
    "    activation_bit_output = {}\n",
    "    weight_word_output = {}\n",
    "    activation_word_output = {}\n",
    "    stats = {}\n",
    "\n",
    "    #Test bit flips (weight)\n",
    "    weight_bit_data   = lfc_mnist_fault_test(\"Weight Bit\", bnn.NETWORK_LFCW1A2, input_file, num_runs, num_flips, False, 0)\n",
    "    weight_bit_output = make_output_dict(\"lfcW1A2\", num_runs, num_flips, accuracy_W1A2_control, {\"weight bit\": weight_bit_data[2]})\n",
    "\n",
    "    write_stats_file(output_folder.format(num_flips) + \"temp/lfcW1A2_results_bit_weight.txt\", weight_bit_output)\n",
    "\n",
    "\n",
    "    #Test bit flips (activation)\n",
    "    activation_bit_data   = lfc_mnist_fault_test(\"Activation Bit\", bnn.NETWORK_LFCW1A2, input_file, num_runs, num_flips, False, 1)\n",
    "    activation_bit_output = make_output_dict(\"lfcW1A2\", num_runs, num_flips, accuracy_W1A2_control, {\"activation bit\": activation_bit_data[2]})\n",
    "\n",
    "    write_stats_file(output_folder.format(num_flips) + \"temp/lfcW1A2_results_bit_activation.txt\", activation_bit_output)\n",
    "\n",
    "\n",
    "    #Test word flips (weight)\n",
    "    weight_word_data   = lfc_mnist_fault_test(\"Weight Word\", bnn.NETWORK_LFCW1A2, input_file, num_runs, num_flips, True, 0)\n",
    "    weight_word_output = make_output_dict(\"lfcW1A2\", num_runs, num_flips, accuracy_W1A2_control, {\"weight word\": weight_word_data[2]})\n",
    "\n",
    "    write_stats_file(output_folder.format(num_flips) + \"temp/lfcW1A2_results_word_weight.txt\", weight_word_output)\n",
    "\n",
    "\n",
    "    #Test word flips (activation)\n",
    "    activation_word_data   = lfc_mnist_fault_test(\"Activation Word\", bnn.NETWORK_LFCW1A2, input_file, num_runs, num_flips, True, 1)\n",
    "    activation_word_output = make_output_dict(\"lfcW1A2\", num_runs, num_flips, accuracy_W1A2_control, {\"activation word\": activation_word_data[2]})\n",
    "\n",
    "    write_stats_file(output_folder.format(num_flips) + \"temp/lfcW1A2_results_word_activation.txt\", activation_word_output)\n",
    "\n",
    "\n",
    "    #Write all stats to file\n",
    "    stats = dict_of_dicts_merge(weight_bit_output, activation_bit_output, weight_word_output, activation_word_output)\n",
    "    stats = calculate_stats(stats)\n",
    "    write_stats_file(output_folder.format(num_flips) + \"lfcW1A2_stats.txt\", stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Run Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_W1A1(num_runs, 1, output_folder)\n",
    "test_W1A2(num_runs, 1, output_folder)\n",
    "\n",
    "test_W1A1(num_runs, 2, output_folder)\n",
    "test_W1A2(num_runs, 2, output_folder)\n",
    "\n",
    "test_W1A1(num_runs, 5, output_folder)\n",
    "test_W1A2(num_runs, 5, output_folder)\n",
    "\n",
    "test_W1A1(num_runs, 10, output_folder)\n",
    "test_W1A2(num_runs, 10, output_folder)\n",
    "\n",
    "test_W1A1(num_runs, 20, output_folder)\n",
    "test_W1A2(num_runs, 20, output_folder)\n",
    "\n",
    "test_W1A1(num_runs, 50, output_folder)\n",
    "test_W1A2(num_runs, 50, output_folder)\n",
    "\n",
    "test_W1A1(num_runs, 100, output_folder)\n",
    "test_W1A2(num_runs, 100, output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
