{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QNN on Pynq\n",
    "\n",
    "This notebook covers how to use low quantized Neural Networks on Pynq for inference on MNIST dataset by using LFC network composed of 4 fully connected layers with 1024 neurons each. There are 2 networks using different precision: \n",
    "\n",
    "- LFCW1A1 using 1 bit weights and 1 activation,\n",
    "- LFCW1A2 using 1 bit weights and 2 activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bnn\n",
    "import os\n",
    "from copy import deepcopy\n",
    "from json import dumps\n",
    "from yapf.yapflib.yapf_api import FormatCode\n",
    "import matplotlib.pyplot as plt\n",
    "from pynq import Xlnk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. LFC and MNIST\n",
    "\n",
    "This notebook performs inference on MNIST test set from http://yann.lecun.com/exdb/mnist/ which contains 10000 pictures of handwritten digits. The LFC network requires MNIST formatted input data, that's why the binary test file can be directly loaded. All other images have to be formatted to this specification (refer to url and LFC webcam examples).\n",
    "\n",
    "At first you need to download mnist test set and labels using wget and unzip the archive as shown below:\n",
    "In order to be able to compare the inferred classes against the expected labels we first read the labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"/home/xilinx/jupyter_notebooks/bnn/t10k-images-idx3-ubyte.gz\"):\n",
    "    #get\n",
    "    !wget http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz \n",
    "    !wget http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz \n",
    "        \n",
    "if not os.path.exists(\"/home/xilinx/jupyter_notebooks/bnn/t10k-images-idx3-ubyte\"):\n",
    "    #unzip    \n",
    "    !gzip -d t10k-images-idx3-ubyte.gz\n",
    "    !gzip -d t10k-labels-idx1-ubyte.gz\n",
    "\n",
    "#read labels\n",
    "labels = []\n",
    "with open(\"/home/xilinx/jupyter_notebooks/bnn/t10k-labels-idx1-ubyte\",\"rb\") as lbl_file:\n",
    "    #read magic number and number of labels (MSB first) -> MNIST header\n",
    "    magicNum = int.from_bytes(lbl_file.read(4), byteorder=\"big\")\n",
    "    countLbl = int.from_bytes(lbl_file.read(4), byteorder=\"big\")\n",
    "    #now the labels are following byte-wise\n",
    "    for idx in range(countLbl):\n",
    "        labels.append(int.from_bytes(lbl_file.read(1), byteorder=\"big\"))\n",
    "    lbl_file.close()\n",
    "len(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Hardware Inference\n",
    "\n",
    "First of all a classifier needs to be instantiated. Using the LfcClassifier will allow to classify MNIST formatted images utilizing LFC network. There are two different runtimes available: hardware accelerated and pure software environment.\n",
    "\n",
    "Once a classifier is instantiated the inference on MNIST images can be started using `classify_mnist` or `classify_mnists` methods - for both single and multiple images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xlnk = Xlnk()\n",
    "\n",
    "num_runs = 200\n",
    "input_file = \"/home/xilinx/jupyter_notebooks/bnn/t10k-images-idx3-ubyte\"\n",
    "output_folder = \"/home/xilinx/jupyter_notebooks/bnn/{}flips/lfc/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(results, labels):\n",
    "    countRight = 0\n",
    "    for idx in range(len(labels)):\n",
    "        if labels[idx] == results[idx]:\n",
    "            countRight += 1\n",
    "    return countRight*100/len(labels)\n",
    "\n",
    "\n",
    "#Merge dictionaries that contain sub-dictionaries\n",
    "def dict_of_dicts_merge(*dicts):\n",
    "    out = {}\n",
    "    for item in dicts:\n",
    "        overlapping_keys = out.keys() & item.keys()\n",
    "        for key in overlapping_keys:\n",
    "            if (isinstance(out[key], dict) and isinstance(item[key], dict)):\n",
    "                out[key] = dict_of_dicts_merge(out[key], item[key])\n",
    "        for key in item.keys() - overlapping_keys:\n",
    "            out[key] = deepcopy(item[key])\n",
    "    return out\n",
    "\n",
    "\n",
    "#Make a dictionary for storing the results, times, or accuracies from a test\n",
    "def make_results_dict(size, targeting_bits_and_words, targeting_weights_and_activations):\n",
    "    if targeting_bits_and_words and targeting_weights_and_activations:\n",
    "        return {\n",
    "            \"bit\": {\n",
    "                \"weight\": [ None for i in range(size) ],\n",
    "                \"activation\": [ None for i in range(size) ],\n",
    "            },\n",
    "            \"word\": {\n",
    "                \"weight\": [ None for i in range(size) ],\n",
    "                \"activation\": [ None for i in range(numsize_runs) ],\n",
    "            },\n",
    "        }\n",
    "    elif targeting_bits_and_words:\n",
    "        return {\n",
    "            \"bit\": [ None for i in range(size) ],\n",
    "            \"word\": [ None for i in range(size) ],\n",
    "        }\n",
    "    elif targeting_weights_and_activations:\n",
    "        return {\n",
    "            \"weight\": [ None for i in range(size) ],\n",
    "            \"activation\": [ None for i in range(numsize_runs) ],\n",
    "        }\n",
    "\n",
    "\n",
    "#Output dict contains the combined raw results from a test. Used as input to calculate_stats\n",
    "def make_output_dict(network_name, num_runs, num_flips, accuracy_control, accuracies_dict):\n",
    "    out = {}\n",
    "    out[\"network\"] = network_name\n",
    "    out[\"run count\"] = num_runs\n",
    "    out[\"flips\"] = num_flips\n",
    "    out[\"control\"] = accuracy_control\n",
    "    out[\"results\"] = {}\n",
    "    for key, val in accuracies_dict.items():\n",
    "        out[\"results\"][key] = val\n",
    "    return out\n",
    "\n",
    "\n",
    "#Calculates various stats given the results of a test (formatted with make_output_dict)\n",
    "def calculate_stats(output_dict):\n",
    "    out = output_dict.copy()\n",
    "    for key, value in output_dict[\"results\"].items():\n",
    "        out[\"results\"][key] = {}\n",
    "        out[\"results\"][key][\"runs\"] = {}\n",
    "        out[\"results\"][key][\"runs\"][\"all\"] = value\n",
    "        out[\"results\"][key][\"runs\"][\"effective\"] = list(filter(lambda x: x != out[\"control\"], value))\n",
    "        out[\"results\"][key][\"effective count\"] = len(out[\"results\"][key][\"runs\"][\"effective\"])\n",
    "        if out[\"results\"][key][\"effective count\"] != 0:\n",
    "            out[\"results\"][key][\"avg accuracy\"] = sum(value) / len(value)\n",
    "            out[\"results\"][key][\"avg effective accuracy\"] = sum(out[\"results\"][key][\"runs\"][\"effective\"]) / out[\"results\"][key][\"effective count\"]\n",
    "            out[\"results\"][key][\"effective accuracy delta\"] = out[\"control\"] - out[\"results\"][key][\"avg effective accuracy\"]\n",
    "        out[\"results\"][key][\"min accuracy\"] = min(value)\n",
    "        out[\"results\"][key][\"max accuracy\"] = max(value)\n",
    "    return out\n",
    "\n",
    "\n",
    "def dict_to_str(dict):\n",
    "    dict_string = dumps(dict)\n",
    "    formatted_code, _ = FormatCode(dict_string)\n",
    "    return formatted_code\n",
    "\n",
    "\n",
    "def write_stats_file(file_name, stats_dict):\n",
    "    os.makedirs(os.path.dirname(file_name), exist_ok=True)\n",
    "    f = open(file_name, \"w+\")\n",
    "    f.write(dict_to_str(stats_dict))\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "\n",
    "### Fault Test Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**lfc_mnist_fault_test:** Classifies the given image set *num_runs* number of times, injecting *num_faults* faults per run. The network is reset between runs.\n",
    "\n",
    "\n",
    "- **title:** The title of the test\n",
    "- **network:** The network to test. e.g. bnn.NETWORK_CNVW1A1\n",
    "- **num_runs:** The number of tests to perform\n",
    "- **num_flips:** The number of faults to inject per run\n",
    "- **flip_word:** A boolean indicating if a bit or word should be flipped\n",
    "- **weight_or_activation:** An integer specifying if weights, activations, or both should be targeted\n",
    "\n",
    "        -1 = target weights and activations\n",
    "        0  = target weights only\n",
    "        1  = target activations only\n",
    "- **target_layers:** An array of integers specifying which layers to target. Leave empty to target all layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lfc_mnist_fault_test(title, network, input_file, num_runs, num_flips, flip_word, weight_or_activation, target_layers = []):\n",
    "    results    = [ None for i in range(num_runs) ]\n",
    "    times      = [ None for i in range(num_runs) ]\n",
    "    accuracies = [ None for i in range(num_runs) ]\n",
    "\n",
    "    for i in range(num_runs):\n",
    "        hw_classifier = bnn.LfcClassifier(network, 'mnist', bnn.RUNTIME_HW)\n",
    "        print(\"{} run {} of {} (flipping {} {}(s) at random times)\".format(title, i+1, num_runs, num_flips, \"word\" if flip_word else \"bit\"))\n",
    "\n",
    "        results[i]    = hw_classifier.classify_mnists_with_faults(input_file, num_flips, flip_word, weight_or_activation, target_layers)\n",
    "        times[i]      = hw_classifier.usecPerImage\n",
    "        accuracies[i] = calculate_accuracy(results[i], labels)\n",
    "\n",
    "        print(\"Accuracy:\", accuracies[i])\n",
    "\n",
    "        xlnk.xlnk_reset()\n",
    "        print()\n",
    "    \n",
    "    return (results, times, accuracies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "\n",
    "### Network Test Functions\n",
    "For each combination of weight/activation and SEU/MBU, the test will be repeated __num_runs__ times and __num_flips__ faults will be injected. The results will be written to files located in __output_folder__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_network(network, control_accuracy, num_runs, num_flips, output_folder):\n",
    "    #Separate output dicts for each run. They will be combined later for the\n",
    "    #final results, and the redundant data will be discarded.\n",
    "    weight_bit_output = {}\n",
    "    activation_bit_output = {}\n",
    "    weight_word_output = {}\n",
    "    activation_word_output = {}\n",
    "    stats = {}\n",
    "    \n",
    "    \n",
    "    #Test bit flips (weight)\n",
    "    weight_bit_data   = lfc_mnist_fault_test(\"Weight Bit\", network, input_file, num_runs, num_flips, False, 0)\n",
    "    weight_bit_output = make_output_dict(network, num_runs, num_flips, control_accuracy, {\"weight bit\": weight_bit_data[2]})\n",
    "\n",
    "    write_stats_file(output_folder.format(num_flips) + \"temp/\" + network + \"_results_bit_weight.json\", weight_bit_output)\n",
    "\n",
    "\n",
    "    #Test bit flips (activation)\n",
    "    activation_bit_data   = lfc_mnist_fault_test(\"Activation Bit\", network, input_file, num_runs, num_flips, False, 1)\n",
    "    activation_bit_output = make_output_dict(network, num_runs, num_flips, control_accuracy, {\"activation bit\": activation_bit_data[2]})\n",
    "\n",
    "    write_stats_file(output_folder.format(num_flips) + \"temp/\" + network + \"_results_bit_activation.json\", activation_bit_output)\n",
    "\n",
    "\n",
    "    #Test word flips (weight)\n",
    "    weight_word_data   = lfc_mnist_fault_test(\"Weight Word\", network, input_file, num_runs, num_flips, True, 0)\n",
    "    weight_word_output = make_output_dict(network, num_runs, num_flips, control_accuracy, {\"weight word\": weight_word_data[2]})\n",
    "\n",
    "    write_stats_file(output_folder.format(num_flips) + \"temp/\" + network + \"_results_word_weight.json\", weight_word_output)\n",
    "\n",
    "\n",
    "    #Test word flips (activation)\n",
    "    activation_word_data   = lfc_mnist_fault_test(\"Activation Word\", network, input_file, num_runs, num_flips, True, 1)\n",
    "    activation_word_output = make_output_dict(network, num_runs, num_flips, control_accuracy, {\"activation word\": activation_word_data[2]})\n",
    "\n",
    "    write_stats_file(output_folder.format(num_flips) + \"temp/\" + network + \"_results_word_activation.json\", activation_word_output)\n",
    "\n",
    "    \n",
    "    #Write all stats to file\n",
    "    stats = dict_of_dicts_merge(weight_bit_output, activation_bit_output, weight_word_output, activation_word_output)\n",
    "    stats = calculate_stats(stats)\n",
    "    write_stats_file(output_folder.format(num_flips) + network + \"_stats.json\", stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_network_layers(network, control_accuracy, num_runs, num_flips, target_layers, output_folder):\n",
    "    weight_bit_output = {}\n",
    "    activation_bit_output = {}\n",
    "    weight_word_output = {}\n",
    "    activation_word_output = {}\n",
    "    stats = {}\n",
    "\n",
    "    #Test weight bit flips\n",
    "    weight_bit_results = lfc_mnist_fault_test(\"Weight Bit {}\".format(target_layers), network, input_file, num_runs, num_flips, False, 0, target_layers)\n",
    "    weight_bit_output  = make_output_dict(network, num_runs, num_flips, control_accuracy, {\"weight bit\": weight_bit_results[2]})\n",
    "    \n",
    "    write_stats_file(output_folder.format(num_flips) + \"temp/layers/\" + network + \"_results_bit_weight_{}.json\".format(target_layers), weight_bit_output)\n",
    "    \n",
    "    \n",
    "    #Test activation bit flips\n",
    "    activation_bit_results = lfc_mnist_fault_test(\"Activation Bit {}\".format(target_layers), network, input_file, num_runs, num_flips, False, 1, target_layers)\n",
    "    activation_bit_output  = make_output_dict(network, num_runs, num_flips, control_accuracy, {\"activation bit\": activation_bit_results[2]})\n",
    "\n",
    "    write_stats_file(output_folder.format(num_flips) + \"temp/layers/\" + network + \"_results_bit_activation_{}.json\".format(target_layers), activation_bit_output)\n",
    "    \n",
    "    \n",
    "    #Test weight word flips\n",
    "    weight_word_results = lfc_mnist_fault_test(\"Weight Word {}\".format(target_layers), network, input_file, num_runs, num_flips, True, 0, target_layers)\n",
    "    weight_word_output  = make_output_dict(network, num_runs, num_flips, control_accuracy, {\"weight word\": weight_word_results[2]})\n",
    "    \n",
    "    write_stats_file(output_folder.format(num_flips) + \"temp/layers/\" + network + \"_results_word_weight_{}.json\".format(target_layers), weight_word_output)\n",
    "    \n",
    "    \n",
    "    #Test activation word flips\n",
    "    activation_word_results = lfc_mnist_fault_test(\"Activation Word {}\".format(target_layers), network, input_file, num_runs, num_flips, True, 1, target_layers)\n",
    "    activation_word_output  = make_output_dict(network, num_runs, num_flips, control_accuracy, {\"activation word\": activation_word_results[2]})\n",
    "\n",
    "    write_stats_file(output_folder.format(num_flips) + \"temp/layers/\" + network + \"_results_word_activation_{}.json\".format(target_layers), activation_word_output)\n",
    "    \n",
    "\n",
    "    #Write all stats to file\n",
    "    stats = dict_of_dicts_merge(weight_bit_output, activation_bit_output, weight_word_output, activation_word_output)\n",
    "    stats = calculate_stats(stats)\n",
    "    write_stats_file(output_folder.format(num_flips) + \"layers/\" + network + \"_stats_layer{}.json\".format(target_layers), stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "\n",
    "### W1A1 - 1 bit weights and 1 bit activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Control run\n",
    "accuracy_W1A1_control = 0\n",
    "result_W1A1_control = None\n",
    "time_W1A1_control = 0\n",
    "\n",
    "#Control test\n",
    "hw_classifier = bnn.LfcClassifier(bnn.NETWORK_LFCW1A1, \"mnist\", bnn.RUNTIME_HW)\n",
    "\n",
    "print(\"Control classification\")\n",
    "result_W1A1_control   = hw_classifier.classify_mnists(input_file)\n",
    "time_W1A1_control     = hw_classifier.usecPerImage\n",
    "accuracy_W1A1_control = calculate_accuracy(result_W1A1_control, labels)\n",
    "print(\"Accuracy:\", accuracy_W1A1_control)\n",
    "\n",
    "#Reset the device\n",
    "xlnk.xlnk_reset()\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### W1A2 - 1 bit weights and 2 bit activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Control run\n",
    "accuracy_W1A2_control = 0\n",
    "result_W1A2_control = None\n",
    "time_W1A2_control = 0\n",
    "\n",
    "#Control test\n",
    "hw_classifier = bnn.LfcClassifier(bnn.NETWORK_LFCW1A2, \"mnist\", bnn.RUNTIME_HW)\n",
    "\n",
    "print(\"Control classification\")\n",
    "result_W1A2_control  = hw_classifier.classify_mnists(input_file)\n",
    "time_W1A2_control     = hw_classifier.usecPerImage\n",
    "accuracy_W1A2_control = calculate_accuracy(result_W1A2_control, labels)\n",
    "print(\"Accuracy:\", accuracy_W1A1_control)\n",
    "\n",
    "#Reset the device\n",
    "xlnk.xlnk_reset()\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "\n",
    "## 3. Run Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flip_counts = [1, 2, 5, 10, 20, 50, 100]\n",
    "\n",
    "for flips in flip_counts:\n",
    "    test_network(bnn.NETWORK_LFCW1A1, accuracy_W1A1_control, 1, flips, output_folder)\n",
    "    test_network(bnn.NETWORK_LFCW1A2, accuracy_W1A2_control, num_runs, flips, output_folder)\n",
    "\n",
    "for flips in flip_counts:\n",
    "    for layer in range(5):\n",
    "        test_network_layers(bnn.NETWORK_LFCW1A1, accuracy_W1A1_control, num_runs, flips, [layer], output_folder)\n",
    "        test_network_layers(bnn.NETWORK_LFCW1A2, accuracy_W1A2_control, num_runs, flips, [layer], output_folder)"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
